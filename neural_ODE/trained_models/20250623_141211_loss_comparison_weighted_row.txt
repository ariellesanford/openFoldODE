EVOFORMER NEURAL ODE TRAINING REPORT
==================================================

Experiment: 20250623_141211_loss_comparison_weighted_row
Started: 2025-06-23 14:12:14
Completed: 2025-06-23 14:23:02
Total Training Time: 10.8 minutes (0.2 hours)
Report generated: 2025-06-23 14:23:02

Configuration Settings:
------------------------------
  data_dirs: ['/media/visitor/Extreme SSD/data/complete_blocks', '/media/visitor/Extreme SSD/data/endpoint_blocks']
  splits_dir: /home/visitor/PycharmProjects/openFold/neural_ODE/data_splits/4n8p
  output_dir: /home/visitor/PycharmProjects/openFold/neural_ODE/trained_models
  experiment_name: 20250623_141211_loss_comparison_weighted_row
  device: cuda
  epochs: 10000
  learning_rate: 0.01
  lr_patience: 3
  lr_factor: 0.5
  min_lr: 1e-06
  early_stopping_patience: 10
  early_stopping_min_delta: 0.0001
  use_fast_ode: False
  loss: weighted_row
  reduced_cluster_size: 64
  hidden_dim: 64
  integrator: rk4
  use_amp: True
  max_residues: 450
  max_time_hours: 0.5
  aggressive_cleanup: True
  enable_preliminary_training: True
  prelim_data_dir: /media/visitor/Extreme SSD/data/complete_blocks
  prelim_block_stride: 4
  prelim_max_epochs: 40
  prelim_chunk_size: 2
  model_parameters: 854854
  model_type: EvoformerODEFunc
  train_proteins: 3
  val_proteins: 3

System Information:
------------------------------
  cuda_available: True
  device: cuda
  pytorch_version: 2.1.2
  gpu_name: Quadro P4000
  cuda_version: 12.1
  total_gpu_memory: 7.9 GB

PRELIMINARY TRAINING PHASE
==================================================

Preliminary Started: 2025-06-23 14:12:14
Preliminary Completed: 2025-06-23 14:22:09
Preliminary Duration: 9.9 minutes

Preliminary Training Progress:
------------------------------
Epoch    Train Loss     Train Success  Val Loss       Val Success    LR           Duration (s)
----------------------------------------------------------------------------------------------------
1        245857.46769   3/3            228672.28334   3/3            1.00e-02     12.7        
2        227966.21723   3/3            237632.81500   3/3            1.00e-02     12.5        
3        219351.29259   3/3            196045.80461   3/3            1.00e-02     12.5        
4        190203.15023   3/3            211698.35506   3/3            1.00e-02     12.5        
5        226504.74818   3/3            212513.57530   3/3            1.00e-02     12.6        
6        267497.70570   3/3            265123.53771   3/3            1.00e-02     12.7        
7        245475.62649   3/3            200122.05328   3/3            5.00e-03     13.7        
8        201289.65725   3/3            256581.51194   3/3            5.00e-03     15.3        
9        254358.22900   3/3            250941.31112   3/3            5.00e-03     15.2        
10       247010.12763   3/3            242454.77743   3/3            2.50e-03     15.3        
11       237280.10910   3/3            228761.61236   3/3            2.50e-03     15.3        
12       212676.81703   3/3            172124.77846   3/3            2.50e-03     15.3        
13       131729.86540   3/3            102839.86567   3/3            2.50e-03     15.2        
14       108993.74683   3/3            101100.35973   3/3            2.50e-03     15.3        
15       96886.08719    3/3            93664.10683    3/3            2.50e-03     15.3        
16       93989.48451    3/3            101910.40234   3/3            2.50e-03     15.3        
17       106108.87481   3/3            99583.50206    3/3            2.50e-03     15.3        
18       99300.14385    3/3            98537.76614    3/3            2.50e-03     15.3        
19       93844.77629    3/3            90401.70860    3/3            1.25e-03     15.3        
20       89632.36825    3/3            88182.26544    3/3            1.25e-03     15.3        
21       88215.28646    3/3            87254.32745    3/3            1.25e-03     15.5        
22       87516.60571    3/3            86869.98150    3/3            1.25e-03     15.3        
23       87188.18541    3/3            86563.61361    3/3            1.25e-03     15.3        
24       86807.50632    3/3            86091.55572    3/3            1.25e-03     15.3        
25       86256.18986    3/3            85523.49438    3/3            1.25e-03     15.3        
26       85699.01364    3/3            84930.25765    3/3            1.25e-03     15.4        
27       85133.52544    3/3            84334.69762    3/3            1.25e-03     15.4        
28       84584.88257    3/3            83788.52886    3/3            1.25e-03     15.3        
29       84197.45239    3/3            83288.82259    3/3            1.25e-03     15.3        
30       84768.31323    3/3            83219.80908    3/3            1.25e-03     15.3        
31       84132.52040    3/3            82646.31028    3/3            1.25e-03     15.3        
32       83609.00616    3/3            82511.30667    3/3            1.25e-03     15.3        
33       83519.17727    3/3            82145.67383    3/3            1.25e-03     15.3        
34       83743.43088    3/3            81715.02818    3/3            1.25e-03     15.4        
35       82637.72713    3/3            81480.95763    3/3            1.25e-03     15.3        
36       82572.37663    3/3            81007.89044    3/3            1.25e-03     15.3        
37       82826.96370    3/3            80692.19227    3/3            1.25e-03     15.3        
38       83719.83412    3/3            79628.98397    3/3            1.25e-03     15.3        
39       83953.68132    3/3            79234.43389    3/3            1.25e-03     15.3        
40       82076.01207    3/3            79542.53624    3/3            1.25e-03     15.3        

MAIN TRAINING PHASE
==================================================

Main Training Started: 2025-06-23 14:22:09
Main Training Completed: 2025-06-23 14:23:02
Main Training Duration: 0.9 minutes

Main Training Progress:
------------------------------
Epoch    Train Loss     Train Success  Val Loss       Val Success    LR           Duration (s)
----------------------------------------------------------------------------------------------------
1        571105.32292   3/3            209544.94271   3/3            1.00e-02     1.9         
2        209544.94271   3/3            209544.94271   3/3            1.00e-02     1.9         
3        176538.48438   3/3            156760.95312   3/3            1.00e-02     1.9         
4        149468.63802   3/3            103353.65104   3/3            1.00e-02     1.9         
5        99232.89583    3/3            91904.99740    3/3            1.00e-02     1.9         
6        90036.64583    3/3            93566.70573    3/3            1.00e-02     1.9         
7        89445.97656    3/3            92551.96094    3/3            1.00e-02     1.9         
8        95711.30990    3/3            90867.55208    3/3            1.00e-02     1.9         
9        89219.03906    3/3            99750.40365    3/3            1.00e-02     1.9         
10       99395.83594    3/3            85300.96875    3/3            1.00e-02     1.9         
11       83795.69271    3/3            83009.88021    3/3            1.00e-02     1.9         
12       81139.56510    3/3            76810.26693    3/3            1.00e-02     1.9         
13       76982.79297    3/3            73320.45052    3/3            1.00e-02     1.9         
14       77705.87109    3/3            75428.24479    3/3            1.00e-02     1.9         
15       76757.77344    3/3            73046.85026    3/3            1.00e-02     1.9         
16       72507.51432    3/3            68620.68099    3/3            1.00e-02     1.9         
17       69247.29948    3/3            65578.23568    3/3            1.00e-02     1.9         
18       60097.26302    3/3            58206.67578    3/3            1.00e-02     1.9         
19       174105.12109   3/3            177618.72917   3/3            1.00e-02     1.9         
20       155176.81250   3/3            85456.79167    3/3            1.00e-02     1.9         
21       140545.86328   3/3            131804.19010   3/3            1.00e-02     1.9         
22       174674.19010   3/3            100517.50781   3/3            5.00e-03     1.9         
23       130076.66667   3/3            101987.05990   3/3            5.00e-03     1.9         
24       148784.95573   3/3            158762.13542   3/3            5.00e-03     1.9         
25       150045.63281   3/3            129398.14062   3/3            2.50e-03     1.9         
26       127102.95052   3/3            102714.99219   3/3            2.50e-03     1.9         
27       108522.17708   3/3            104337.08594   3/3            2.50e-03     1.9         
28       106924.35417   3/3            105022.16146   3/3            1.25e-03     1.9         

OVERALL PERFORMANCE ANALYSIS
------------------------------
Best Overall Epoch: Main Epoch 18 (Loss: 60097.26302)
Worst Overall Epoch: Main Epoch 1 (Loss: 571105.32292)
Overall Training Improvement: 9.5x better from worst to best
Final Training Success Rate: 100.0%
Final Validation Success Rate: 100.0%
Final Learning Rate: 1.25e-03

FINAL MODEL
------------------------------
Model saved to: /home/visitor/PycharmProjects/openFold/neural_ODE/trained_models/20250623_141211_loss_comparison_weighted_row_final_model.pt
Total parameters: 854854
Model type: EvoformerODEFunc

==================================================
