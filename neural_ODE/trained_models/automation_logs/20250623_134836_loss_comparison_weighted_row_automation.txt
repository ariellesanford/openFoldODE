Experiment: Loss Comparison: Weighted Row
Actual experiment name: 20250623_134836_loss_comparison_weighted_row
Started: 2025-06-23 13:48:36
Ended: 2025-06-23 13:53:16
Duration: 0.08 hours
Return code: 1
Command: /home/visitor/anaconda3/envs/openfold_env/bin/python train_evoformer_ode.py --data_dirs /media/visitor/Extreme SSD/data/complete_blocks /media/visitor/Extreme SSD/data/endpoint_blocks --splits_dir /home/visitor/PycharmProjects/openFold/neural_ODE/data_splits/4n8p --device cuda --epochs 10000 --learning_rate 0.01 --reduced_cluster_size 64 --hidden_dim 64 --integrator rk4 --loss weighted_row --max_residues 450 --output_dir /home/visitor/PycharmProjects/openFold/neural_ODE/trained_models --experiment_name 20250623_134836_loss_comparison_weighted_row --lr_patience 3 --lr_factor 0.5 --min_lr 1e-06 --early_stopping_patience 10 --early_stopping_min_delta 0.0001 --max_time_hours 0.5 --prelim_data_dir /media/visitor/Extreme SSD/data/complete_blocks --prelim_block_stride 4 --prelim_max_epochs 40 --prelim_chunk_size 2 --use_amp --aggressive_cleanup --enable_preliminary_training

CONFIGURATION:
  data_dirs: ['/media/visitor/Extreme SSD/data/complete_blocks', '/media/visitor/Extreme SSD/data/endpoint_blocks']
  splits_dir: /home/visitor/PycharmProjects/openFold/neural_ODE/data_splits/4n8p
  device: cuda
  epochs: 10000
  learning_rate: 0.01
  reduced_cluster_size: 64
  hidden_dim: 64
  integrator: rk4
  use_fast_ode: False
  max_residues: 450
  loss: weighted_row
  use_amp: True
  output_dir: /home/visitor/PycharmProjects/openFold/neural_ODE/trained_models
  lr_patience: 3
  lr_factor: 0.5
  min_lr: 1e-06
  early_stopping_patience: 10
  early_stopping_min_delta: 0.0001
  max_time_hours: 0.5
  aggressive_cleanup: True
  enable_preliminary_training: True
  prelim_data_dir: /media/visitor/Extreme SSD/data/complete_blocks
  prelim_block_stride: 4
  prelim_max_epochs: 40
  prelim_chunk_size: 2
  experiment_name: 20250623_134836_loss_comparison_weighted_row

OUTPUT:
[2025-06-23 13:48:38,245] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ğŸš€ Neural ODE Training - Restructured Version
ğŸ“ Data directories: ['/media/visitor/Extreme SSD/data/complete_blocks', '/media/visitor/Extreme SSD/data/endpoint_blocks']
ğŸ’» Device: cuda
ğŸ”§ Model: Full ODE
ğŸ”„ Preliminary training enabled
ğŸ” Filtering 3 proteins by size (max: 450 residues)
  âœ… 4n8p_A: 135 residues
  âœ… 4ekx_A: 116 residues
  âœ… 7k6p_A: 98 residues
ğŸ“Š Kept 3/3 proteins
ğŸ” Filtering 3 proteins by size (max: 450 residues)
  âœ… 4n8p_A: 135 residues
  âœ… 4ekx_A: 116 residues
  âœ… 7k6p_A: 98 residues
ğŸ“Š Kept 3/3 proteins
ğŸ¤– Model: 854854 parameters
ğŸ§¬ Training proteins: 3
ğŸ” Validation proteins: 3

ğŸš€ PRELIMINARY TRAINING PHASE
============================================================
ğŸ” Filtering 3 proteins by size (max: 450 residues)
  âœ… 4n8p_A: 135 residues
  âœ… 4ekx_A: 116 residues
  âœ… 7k6p_A: 98 residues
ğŸ“Š Kept 3/3 proteins
ğŸ” Filtering 3 proteins by size (max: 450 residues)
  âœ… 4n8p_A: 135 residues
  âœ… 4ekx_A: 116 residues
  âœ… 7k6p_A: 98 residues
ğŸ“Š Kept 3/3 proteins

ğŸ“ˆ Preliminary Epoch 1/40
ğŸ›ï¸  LR: 1.00e-02
  [1/3] 4n8p_A... âœ… Loss: 342945.92725
  [2/3] 4ekx_A... âœ… Loss: 241984.02653
  [3/3] 7k6p_A... âœ… Loss: 189989.09440
ğŸ“Š Training: 258306.34939 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 336379.84391
    [2/3] 4ekx_A... âœ… Loss: 288408.39144
    [3/3] 7k6p_A... âœ… Loss: 256604.14209
ğŸ“ˆ New best validation loss: 293797.4591

ğŸ“ˆ Preliminary Epoch 2/40
ğŸ›ï¸  LR: 1.00e-02
  [1/3] 4n8p_A... âœ… Loss: 251335.86084
  [2/3] 4ekx_A... âœ… Loss: 231573.21354
  [3/3] 7k6p_A... âœ… Loss: 144400.98918
ğŸ“Š Training: 209103.35452 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 189417.25732
    [2/3] 4ekx_A... âœ… Loss: 162152.96989
    [3/3] 7k6p_A... âœ… Loss: 143122.84814
ğŸ“ˆ New best validation loss: 164897.6918

ğŸ“ˆ Preliminary Epoch 3/40
ğŸ›ï¸  LR: 1.00e-02
  [1/3] 4n8p_A... âœ… Loss: 191989.13558
  [2/3] 4ekx_A... âœ… Loss: 178503.26367
  [3/3] 7k6p_A... âœ… Loss: 174733.76099
ğŸ“Š Training: 181742.05341 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 204083.49772
    [2/3] 4ekx_A... âœ… Loss: 179514.36833
    [3/3] 7k6p_A... âœ… Loss: 162009.69873

ğŸ“ˆ Preliminary Epoch 4/40
ğŸ›ï¸  LR: 1.00e-02
  [1/3] 4n8p_A... âœ… Loss: 181252.88477
  [2/3] 4ekx_A... âœ… Loss: 233151.46029
  [3/3] 7k6p_A... âœ… Loss: 196518.47274
ğŸ“Š Training: 203640.93926 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 291845.10042
    [2/3] 4ekx_A... âœ… Loss: 262650.63005
    [3/3] 7k6p_A... âœ… Loss: 227332.86466

ğŸ“ˆ Preliminary Epoch 5/40
ğŸ›ï¸  LR: 1.00e-02
  [1/3] 4n8p_A... âœ… Loss: 224306.83382
  [2/3] 4ekx_A... âœ… Loss: 202612.07389
  [3/3] 7k6p_A... âœ… Loss: 178511.96387
ğŸ“Š Training: 201810.29053 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 196235.25098
    [2/3] 4ekx_A... âœ… Loss: 169939.93205
    [3/3] 7k6p_A... âœ… Loss: 148440.88883
ğŸ”½ Learning rate reduced: 1.00e-02 â†’ 5.00e-03

ğŸ“ˆ Preliminary Epoch 6/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 179625.12337
  [2/3] 4ekx_A... âœ… Loss: 144773.82414
  [3/3] 7k6p_A... âœ… Loss: 131887.30729
ğŸ“Š Training: 152095.41827 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 150485.33496
    [2/3] 4ekx_A... âœ… Loss: 130748.63924
    [3/3] 7k6p_A... âœ… Loss: 121481.46094
ğŸ“ˆ New best validation loss: 134238.4784

ğŸ“ˆ Preliminary Epoch 7/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 150368.98730
  [2/3] 4ekx_A... âœ… Loss: 127839.50749
  [3/3] 7k6p_A... âœ… Loss: 115686.81152
ğŸ“Š Training: 131298.43544 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 163326.67171
    [2/3] 4ekx_A... âœ… Loss: 138779.70785
    [3/3] 7k6p_A... âœ… Loss: 128585.32707

ğŸ“ˆ Preliminary Epoch 8/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 147024.28727
  [2/3] 4ekx_A... âœ… Loss: 136552.06665
  [3/3] 7k6p_A... âœ… Loss: 106016.82975
ğŸ“Š Training: 129864.39456 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 144277.99772
    [2/3] 4ekx_A... âœ… Loss: 125016.84538
    [3/3] 7k6p_A... âœ… Loss: 117189.64933
ğŸ“ˆ New best validation loss: 128828.1641

ğŸ“ˆ Preliminary Epoch 9/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 147027.27962
  [2/3] 4ekx_A... âœ… Loss: 112492.41414
  [3/3] 7k6p_A... âœ… Loss: 94044.35042
ğŸ“Š Training: 117854.68140 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 121890.46354
    [2/3] 4ekx_A... âœ… Loss: 103176.35962
    [3/3] 7k6p_A... âœ… Loss: 92600.56136
ğŸ“ˆ New best validation loss: 105889.1282

ğŸ“ˆ Preliminary Epoch 10/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 118295.97428
  [2/3] 4ekx_A... âœ… Loss: 110494.90828
  [3/3] 7k6p_A... âœ… Loss: 98420.89844
ğŸ“Š Training: 109070.59367 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 127650.56429
    [2/3] 4ekx_A... âœ… Loss: 108049.24797
    [3/3] 7k6p_A... âœ… Loss: 91743.96167

ğŸ“ˆ Preliminary Epoch 11/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 122454.07633
  [2/3] 4ekx_A... âœ… Loss: 126198.88550
  [3/3] 7k6p_A... âœ… Loss: 95340.89209
ğŸ“Š Training: 114664.61797 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 115000.34717
    [2/3] 4ekx_A... âœ… Loss: 95935.65853
    [3/3] 7k6p_A... âœ… Loss: 85965.18831
ğŸ“ˆ New best validation loss: 98967.0647

ğŸ“ˆ Preliminary Epoch 12/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 148701.99072
  [2/3] 4ekx_A... âœ… Loss: 102177.55697
  [3/3] 7k6p_A... âœ… Loss: 258848.12598
ğŸ“Š Training: 169909.22456 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 148747.18262
    [2/3] 4ekx_A... âœ… Loss: 127508.88924
    [3/3] 7k6p_A... âœ… Loss: 121828.43172

ğŸ“ˆ Preliminary Epoch 13/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 141438.83919
  [2/3] 4ekx_A... âœ… Loss: 129159.59855
  [3/3] 7k6p_A... âœ… Loss: 102856.04500
ğŸ“Š Training: 124484.82758 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 140547.66292
    [2/3] 4ekx_A... âœ… Loss: 116133.47965
    [3/3] 7k6p_A... âœ… Loss: 106766.83545

ğŸ“ˆ Preliminary Epoch 14/40
ğŸ›ï¸  LR: 5.00e-03
  [1/3] 4n8p_A... âœ… Loss: 163098.16520
  [2/3] 4ekx_A... âœ… Loss: 136936.68953
  [3/3] 7k6p_A... âœ… Loss: 132431.36279
ğŸ“Š Training: 144155.40584 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 173671.56844
    [2/3] 4ekx_A... âœ… Loss: 153127.09131
    [3/3] 7k6p_A... âœ… Loss: 126797.60799
ğŸ”½ Learning rate reduced: 5.00e-03 â†’ 2.50e-03

ğŸ“ˆ Preliminary Epoch 15/40
ğŸ›ï¸  LR: 2.50e-03
  [1/3] 4n8p_A... âœ… Loss: 161249.52905
  [2/3] 4ekx_A... âœ… Loss: 107398.39681
  [3/3] 7k6p_A... âœ… Loss: 83197.96549
ğŸ“Š Training: 117281.96379 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 102745.64518
    [2/3] 4ekx_A... âœ… Loss: 86560.78182
    [3/3] 7k6p_A... âœ… Loss: 79780.03198
ğŸ“ˆ New best validation loss: 89695.4863

ğŸ“ˆ Preliminary Epoch 16/40
ğŸ›ï¸  LR: 2.50e-03
  [1/3] 4n8p_A... âœ… Loss: 103379.84066
  [2/3] 4ekx_A... âœ… Loss: 82632.76562
  [3/3] 7k6p_A... âœ… Loss: 76961.93864
ğŸ“Š Training: 87658.18164 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 97624.44792
    [2/3] 4ekx_A... âœ… Loss: 82235.61548
    [3/3] 7k6p_A... âœ… Loss: 75442.73568
ğŸ“ˆ New best validation loss: 85100.9330

ğŸ“ˆ Preliminary Epoch 17/40
ğŸ›ï¸  LR: 2.50e-03
  [1/3] 4n8p_A... âœ… Loss: 98072.00049
  [2/3] 4ekx_A... âœ… Loss: 79979.27173
  [3/3] 7k6p_A... âœ… Loss: 76021.82389
ğŸ“Š Training: 84691.03204 (3/3)

ğŸ” Preliminary validation on 3 proteins...
    [1/3] 4n8p_A... âœ… Loss: 97081.52808
    [2/3] 4ekx_A... âœ… Loss: 81615.09424
    [3/3] 7k6p_A... âœ… Loss: 74447.16398
ğŸ“ˆ New best validation loss: 84381.2621

ğŸ“ˆ Preliminary Epoch 18/40
ğŸ›ï¸  LR: 2.50e-03
  [1/3] 4n8p_A... âœ… Loss: 100030.33732
  [2/3] 4ekx_A... âœ… Loss: 78867.26945
  [3/3] 7k6p_A... âœ… Loss: nan
âš ï¸  NaN/Inf training loss detected! (1/3)
ğŸ”½ Emergency LR reduction: 1.25e-03

ğŸ“ˆ Preliminary Epoch 19/40
ğŸ›ï¸  LR: 1.25e-03
  [1/3] 4n8p_A... âœ… Loss: nan
  [2/3] 4ekx_A... âœ… Loss: nan
  [3/3] 7k6p_A... âœ… Loss: nan
âš ï¸  NaN/Inf training loss detected! (2/3)
ğŸ”½ Emergency LR reduction: 6.25e-04

ğŸ“ˆ Preliminary Epoch 20/40
ğŸ›ï¸  LR: 6.25e-04
  [1/3] 4n8p_A... âœ… Loss: nan
  [2/3] 4ekx_A... âœ… Loss: nan
  [3/3] 7k6p_A... âœ… Loss: nan
âš ï¸  NaN/Inf training loss detected! (3/3)
âŒ Too many consecutive NaN epochs, stopping preliminary training
Traceback (most recent call last):
  File "/home/visitor/PycharmProjects/openFold/neural_ODE/train_evoformer_ode.py", line 1198, in <module>
    main()
  File "/home/visitor/PycharmProjects/openFold/neural_ODE/train_evoformer_ode.py", line 1089, in main
    success = run_preliminary_training(config, model, optimizer, scaler, logger)
  File "/home/visitor/PycharmProjects/openFold/neural_ODE/train_evoformer_ode.py", line 1004, in run_preliminary_training
    print(f"ğŸ›ï¸  Restoring original LR for main training: {optimizer.param_groups[0]['lr']:.2e} â†’ {original_lr:.2e}")
NameError: name 'original_lr' is not defined
