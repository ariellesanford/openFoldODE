EVOFORMER ODE MEMORY OPTIMIZATION REPORT
========================================
#Using the full evoformer??
System Information:
  CUDA Available: True
  GPU: Quadro P4000
  CUDA Version: 12.1
  PyTorch Version: 2.1.2


============================================================
CONFIGURATION TEST SUMMARY
============================================================

Name                      Status     Memory (MB)  Time (ms)    Loss      
--------------------------------------------------------------------------------
True Baseline (Original   SUCCESS    3411.62      57562.40     18.1451   
AMP Only                  SUCCESS    1773.84      92893.46     18.1515   
Checkpoint Only           FAILED (Timeout) N/A          N/A          N/A       
Memory Optimized Baselin  FAILED (Timeout) N/A          N/A          N/A       
Speed-Optimized           SUCCESS    382.99       2298.94      40.8004   
Balanced Speed-Quality    FAILED (Timeout) N/A          N/A          N/A       

============================================================
BEST CONFIGURATIONS
============================================================

üèÜ Best Memory Efficiency:
   Name: Speed-Optimized
   Memory: 382.99 MB
   Time: 2298.94 ms
   Loss: 40.8004

üèÜ Best Speed:
   Name: Speed-Optimized
   Memory: 382.99 MB
   Time: 2298.94 ms
   Loss: 40.8004

üèÜ Best Loss Performance:
   Name: True Baseline (Original values, no optimizations)
   Memory: 3411.62 MB
   Time: 57562.40 ms
   Loss: 18.1451

üèÜ Best Balance (Memory + Speed):
   Name: Speed-Optimized
   Memory: 382.99 MB
   Time: 2298.94 ms
   Loss: 40.8004

============================================================

Detailed Configuration Results:
----------------------------------------

Configuration 1: True Baseline (Original values, no optimizations)
  Status: SUCCESS
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 64
    reduced_hidden_dim: 64
    num_time_points: 25
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 0
    enabled flags: monitor_memory, test-single-step
    disabled flags: use_amp, use_checkpoint, reduced_precision_integration, clean_memory
  Results:
    Loss: 18.145058
    Max Memory: 3411.62 MB
    Time: 57562.40 ms

Configuration 2: AMP Only
  Status: SUCCESS
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 64
    reduced_hidden_dim: 64
    num_time_points: 25
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 0
    enabled flags: use_amp, monitor_memory, test-single-step
    disabled flags: use_checkpoint, reduced_precision_integration, clean_memory
  Results:
    Loss: 18.151549
    Max Memory: 1773.84 MB
    Time: 92893.46 ms

Configuration 3: Checkpoint Only
  Status: FAILED
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 64
    reduced_hidden_dim: 64
    num_time_points: 25
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 0
    enabled flags: use_checkpoint, monitor_memory, test-single-step
    disabled flags: use_amp, reduced_precision_integration, clean_memory
  Error: Timeout

Configuration 4: Memory Optimized Baseline
  Status: FAILED
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 96
    reduced_hidden_dim: 96
    num_time_points: 25
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 0
    enabled flags: use_amp, use_checkpoint, monitor_memory, test-single-step
    disabled flags: reduced_precision_integration, clean_memory
  Error: Timeout

Configuration 5: Speed-Optimized
  Status: SUCCESS
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 64
    reduced_hidden_dim: 64
    num_time_points: 15
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 0
    enabled flags: use_amp, use_checkpoint, reduced_precision_integration, monitor_memory, test-single-step, use_fast_ode
    disabled flags: clean_memory
  Results:
    Loss: 40.800425
    Max Memory: 382.99 MB
    Time: 2298.94 ms

Configuration 6: Balanced Speed-Quality
  Status: FAILED
  Settings:
    memory_split_size: 128
    reduced_cluster_size: 80
    reduced_hidden_dim: 80
    num_time_points: 20
    batch_size: 1
    integrator: rk4
    gradient_accumulation: 1
    chunk_size: 5
    enabled flags: use_amp, use_checkpoint, monitor_memory, test-single-step
    disabled flags: reduced_precision_integration, clean_memory
  Error: Timeout

========================================
Report generated at: 2025-05-19 16:53:25
