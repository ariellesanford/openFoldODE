import os
import gc
import torch
import argparse
import sys
import subprocess  # Add missing import
from torchdiffeq import odeint
import torch.optim as optim
from evoformer_ode import EvoformerODEFunc, EvoformerODEFuncFast  # Import from existing module
from torch.cuda.amp import autocast, GradScaler
from torch.utils.checkpoint import checkpoint
import torch.nn.functional as F
import json
import time
from pathlib import Path


# Function to get project root directory
def get_project_root():
    """Get the path to the project root directory."""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return current_dir


# === Parse command line arguments to match run_training.sh ===
parser = argparse.ArgumentParser(description='Train Evoformer ODE - Compatible with run_training.sh')

# Data directory options
parser.add_argument('--data_dir', type=str, default=None,
                    help='Path to data directory')
parser.add_argument('--output_dir', type=str, default=None,
                    help='Path to output directory')

# Model options
parser.add_argument('--use_fast_ode', action='store_true', default=False,
                    help='Use the faster implementation of EvoformerODEFunc')
parser.add_argument('--no-use_fast_ode', dest='use_fast_ode', action='store_false',
                    help='Disable fast ODE implementation')

# Memory and model size options
parser.add_argument('--memory_split_size', type=int, default=128,
                    help='Memory split size (MB) - for compatibility')
parser.add_argument('--reduced_cluster_size', type=int, default=32,
                    help='Maximum cluster size')
parser.add_argument('--reduced_hidden_dim', type=int, default=32,
                    help='Hidden dimension size')

# Training options
parser.add_argument('--learning_rate', type=float, default=1e-5,
                    help='Learning rate for the optimizer')
parser.add_argument('--num_time_points', type=int, default=5,
                    help='Number of integration time points')
parser.add_argument('--batch_size', type=int, default=1,
                    help='Batch size (for compatibility)')
parser.add_argument('--integrator', choices=['dopri5', 'rk4', 'euler'], default='euler',
                    help='ODE integrator method')
parser.add_argument('--gradient_accumulation', type=int, default=1,
                    help='Gradient accumulation steps (for compatibility)')
parser.add_argument('--chunk_size', type=int, default=0,
                    help='Chunk size (for compatibility)')
parser.add_argument('--epochs', type=int, default=5,
                    help='Number of training epochs')

# Optimization flags
parser.add_argument('--use_amp', action='store_true', default=False,
                    help='Use Automatic Mixed Precision')
parser.add_argument('--no-use_amp', dest='use_amp', action='store_false',
                    help='Disable AMP')
parser.add_argument('--use_checkpoint', action='store_true', default=False,
                    help='Use gradient checkpointing')
parser.add_argument('--no-use_checkpoint', dest='use_checkpoint', action='store_false',
                    help='Disable checkpointing')
parser.add_argument('--monitor_memory', action='store_true', default=False,
                    help='Monitor memory usage')
parser.add_argument('--no-monitor_memory', dest='monitor_memory', action='store_false',
                    help='Disable memory monitoring')
parser.add_argument('--clean_memory', action='store_true', default=False,
                    help='Clean memory aggressively')
parser.add_argument('--no-clean_memory', dest='clean_memory', action='store_false',
                    help='Disable memory cleaning')
parser.add_argument('--reduced_precision_integration', action='store_true', default=False,
                    help='Use reduced precision integration')
parser.add_argument('--no-reduced_precision_integration', dest='reduced_precision_integration',
                    action='store_false', help='Disable reduced precision')

# Device options
parser.add_argument('--cpu_only', action='store_true', default=False,
                    help='Force CPU-only mode')
parser.add_argument('--no-cpu-only', dest='cpu_only', action='store_false',
                    help='Disable CPU-only mode')

# Test options (for compatibility)
parser.add_argument('--test-protein', type=str, default=None,
                    help='Test specific protein (for compatibility)')

# Additional options
parser.add_argument('--max_iterations', type=int, default=10,
                    help='Maximum iterations (for compatibility)')
parser.add_argument('--config_preset', type=str, default='model_1_ptm',
                    help='Config preset (for compatibility)')
parser.add_argument('--device', type=str, default='cuda:0',
                    help='Device (for compatibility)')

# Parse arguments
args = parser.parse_args()

# === Configuration ===
PROJECT_ROOT = get_project_root()

# Set data directory
if args.data_dir is None:
    DATA_DIR = os.path.join(PROJECT_ROOT, "data")
else:
    DATA_DIR = args.data_dir

if args.output_dir is None:
    OUTPUT_DIR = os.path.join(PROJECT_ROOT, "outputs")
else:
    OUTPUT_DIR = args.output_dir

# Create output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Device configuration
if args.cpu_only:
    device = "cpu"
    args.use_amp = False
else:
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if device == "cpu":
        args.use_amp = False

print(f"üöÄ Evoformer ODE Training")
print(f"üìÅ Data directory: {DATA_DIR}")
print(f"üíæ Output directory: {OUTPUT_DIR}")
print(f"üíª Device: {device}")
print(f"‚öôÔ∏è  Configuration:")
print(f"   Learning rate: {args.learning_rate}")
print(f"   Epochs: {args.epochs}")
print(f"   Time points: {args.num_time_points}")
print(f"   Cluster size: {args.reduced_cluster_size}")
print(f"   Hidden dim: {args.reduced_hidden_dim}")
print(f"   Use fast ODE: {args.use_fast_ode}")
print(f"   Use AMP: {args.use_amp}")

# Model configuration
c_m = 256  # MSA (M) channels
c_z = 128  # Pair (Z) channels
hidden_dim = args.reduced_hidden_dim
learning_rate = args.learning_rate
epochs = args.epochs

# Setup gradient scaler for mixed precision
scaler = GradScaler(enabled=args.use_amp and device == "cuda")


def clear_memory():
    """Clear memory safely"""
    if args.clean_memory:
        gc.collect()
        if device == "cuda":
            torch.cuda.empty_cache()


def print_memory_stats(label=""):
    """Print memory statistics if monitoring is enabled"""
    if not args.monitor_memory:
        return

    if device == "cpu":
        print(f"=== Memory Stats {label} (CPU mode) ===")
        return

    try:
        torch.cuda.synchronize()
        allocated = torch.cuda.memory_allocated() / 1024 ** 2
        reserved = torch.cuda.memory_reserved() / 1024 ** 2
        print(f"=== Memory Stats {label} ===")
        print(f"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB")
    except Exception as e:
        print(f"Memory stats error: {e}")


def get_dataset(input_dir):
    """Get all protein folder names that contain evoformer blocks data"""
    datasets = []
    input_path = Path(input_dir)

    if not input_path.exists():
        print(f"‚ùå Data directory not found: {input_dir}")
        return datasets

    # Handle different directory structures
    if (input_path / "training").exists() or (input_path / "validation").exists():
        # Mini-data structure with splits
        for split in ['training', 'validation', 'testing']:
            split_dir = input_path / split / 'blocks'
            if split_dir.exists():
                for protein_dir in split_dir.iterdir():
                    if (protein_dir.is_dir() and
                            protein_dir.name.endswith('_evoformer_blocks') and
                            (protein_dir / 'recycle_0').exists()):
                        protein_id = protein_dir.name.replace('_evoformer_blocks', '')
                        datasets.append(protein_id)
    else:
        # Standard structure - all proteins in one directory
        for protein_dir in input_path.iterdir():
            if (protein_dir.is_dir() and
                    protein_dir.name.endswith('_evoformer_blocks') and
                    (protein_dir / 'recycle_0').exists()):
                protein_id = protein_dir.name.replace('_evoformer_blocks', '')
                datasets.append(protein_id)

    return datasets


def find_protein_data(protein_id, data_dir):
    """Find protein data in various possible locations"""
    data_path = Path(data_dir)

    # Possible locations for the protein data
    possible_locations = [
        # Direct in data directory
        data_path / f"{protein_id}_evoformer_blocks" / "recycle_0",
        # In splits
        data_path / "training" / "blocks" / f"{protein_id}_evoformer_blocks" / "recycle_0",
        data_path / "validation" / "blocks" / f"{protein_id}_evoformer_blocks" / "recycle_0",
        data_path / "testing" / "blocks" / f"{protein_id}_evoformer_blocks" / "recycle_0",
    ]

    for location in possible_locations:
        if location.exists():
            return location

    return None


def load_initial_input(protein_id):
    """Load the initial M and Z tensors for block 0"""
    protein_dir = find_protein_data(protein_id, DATA_DIR)

    if protein_dir is None:
        raise FileNotFoundError(f"Data not found for {protein_id}")

    m_path = protein_dir / "m_block_0.pt"
    z_path = protein_dir / "z_block_0.pt"

    if not m_path.exists() or not z_path.exists():
        raise FileNotFoundError(f"Initial block files not found for {protein_id}")

    # Load tensors
    m_init = torch.load(m_path, map_location=device)
    z_init = torch.load(z_path, map_location=device)

    print(f"    üìè Raw loaded shapes: m={list(m_init.shape)}, z={list(z_init.shape)}")

    # Remove batch dimension if present
    if m_init.dim() == 4 and m_init.size(0) == 1:
        m_init = m_init.squeeze(0)
        print(f"    üì¶ Removed batch dim: m={list(m_init.shape)}")
    if z_init.dim() == 4 and z_init.size(0) == 1:
        z_init = z_init.squeeze(0)
        print(f"    üì¶ Removed batch dim: z={list(z_init.shape)}")

    # Reduce cluster size (MSA sequences, not residue length!)
    original_cluster_size = m_init.shape[0]
    if original_cluster_size > args.reduced_cluster_size:
        m_init = m_init[:args.reduced_cluster_size]
        print(f"    ‚úÇÔ∏è  Reduced cluster size: {original_cluster_size} ‚Üí {args.reduced_cluster_size}")

    print(f"    üìä Final shapes: m={list(m_init.shape)}, z={list(z_init.shape)}")

    return m_init, z_init


def load_block(protein_id, block_index):
    """Load M and Z tensors for a specific block index"""
    protein_dir = find_protein_data(protein_id, DATA_DIR)

    if protein_dir is None:
        raise FileNotFoundError(f"Data not found for {protein_id}")

    m_path = protein_dir / f"m_block_{block_index}.pt"
    z_path = protein_dir / f"z_block_{block_index}.pt"

    if not m_path.exists() or not z_path.exists():
        raise FileNotFoundError(f"Block {block_index} not found for {protein_id}")

    # Load tensors
    m = torch.load(m_path, map_location=device)
    z = torch.load(z_path, map_location=device)

    # Remove batch dimension if present
    if m.dim() == 4 and m.size(0) == 1:
        m = m.squeeze(0)
    if z.dim() == 4 and z.size(0) == 1:
        z = z.squeeze(0)

    # Reduce cluster size
    m = m[:args.reduced_cluster_size]

    return m, z


def balanced_loss_fn(pred_m, target_m, pred_z, target_z, msa_weight=1.0, pair_weight=0.1):
    """Balanced loss function that handles size mismatches from truncation"""

    # Handle size mismatches due to sequence length truncation
    pred_seq_len = pred_m.shape[1]
    target_seq_len = target_m.shape[1]

    if pred_seq_len != target_seq_len:
        print(f"        üîß Size mismatch detected: pred={pred_seq_len}, target={target_seq_len}")

        # Use the minimum length to avoid index errors
        min_len = min(pred_seq_len, target_seq_len)

        # Truncate both to the same size
        pred_m = pred_m[:, :min_len, :]
        target_m = target_m[:, :min_len, :]
        pred_z = pred_z[:min_len, :min_len, :]
        target_z = target_z[:min_len, :min_len, :]

        print(f"        ‚úÇÔ∏è  Truncated both to {min_len} residues for loss computation")

    msa_loss = F.mse_loss(pred_m, target_m)
    pair_loss = F.mse_loss(pred_z, target_z)
    weighted_loss = msa_weight * msa_loss + pair_weight * pair_loss

    return weighted_loss, msa_loss.item(), pair_loss.item()


# Initialize model
if args.use_fast_ode:
    print("Using FAST EvoformerODEFunc implementation")
    ode_func = EvoformerODEFuncFast(c_m, c_z, hidden_dim).to(device)
else:
    print("Using standard EvoformerODEFunc implementation")
    ode_func = EvoformerODEFunc(c_m, c_z, hidden_dim).to(device)

optimizer = torch.optim.Adam(ode_func.parameters(), lr=learning_rate)

# Time grid for integration
t_grid = torch.linspace(0, 1, args.num_time_points).to(device)


class EvoformerIterationManager:
    """Manages calling evoformer_iter to generate next time steps on-demand"""

    def __init__(self, project_root, config_preset='model_1_ptm', device='cuda:0'):
        self.project_root = Path(project_root)
        self.config_preset = config_preset
        self.device = device

        # Find the evoformer iteration script
        # evoformer_iter is at the same level as neural_ODE, not inside it
        possible_scripts = [
            # Try Python script first (more reliable)
            self.project_root.parent / "evoformer_iter" / "run_evoformer_iter.py",  # Go up one level
            self.project_root / "evoformer_iter" / "run_evoformer_iter.py",  # Current level (fallback)
            self.project_root / "run_evoformer_iter.py",  # Direct in neural_ODE
            # Then shell script
            self.project_root.parent / "evoformer_iter_script.sh",  # Go up one level
            self.project_root / "evoformer_iter_script.sh",  # Current level (fallback)
        ]

        self.iter_script = None
        for script_path in possible_scripts:
            if script_path.exists():
                self.iter_script = script_path
                break

        if self.iter_script is None:
            raise FileNotFoundError("Could not find evoformer iteration script")

        print(f"    üìú Using evoformer script: {self.iter_script}")

    def generate_next_iteration(self, protein_id: str, current_idx: int) -> tuple:
        """Generate the next Evoformer iteration and return the tensors"""

        # Find the protein directory
        protein_dir = find_protein_data(protein_id, DATA_DIR)
        if protein_dir is None:
            raise FileNotFoundError(f"Protein data not found for {protein_id}")

        # Check if current files exist
        m_current = protein_dir / f"m_block_{current_idx}.pt"
        z_current = protein_dir / f"z_block_{current_idx}.pt"

        if not (m_current.exists() and z_current.exists()):
            raise FileNotFoundError(f"Current iteration files not found: {m_current}, {z_current}")

        # Check if next iteration already exists
        m_next = protein_dir / f"m_block_{current_idx + 1}.pt"
        z_next = protein_dir / f"z_block_{current_idx + 1}.pt"

        if m_next.exists() and z_next.exists():
            print(f"        ‚úÖ Next iteration {current_idx + 1} already exists")
            return self._load_iteration(m_next, z_next)

        # Generate next iteration using evoformer_iter
        print(f"        üîÑ Generating iteration {current_idx + 1} using evoformer_iter...")
        success = self._run_evoformer_iter(m_current, z_current, protein_dir)

        if success and m_next.exists() and z_next.exists():
            return self._load_iteration(m_next, z_next)
        else:
            raise RuntimeError(f"Failed to generate iteration {current_idx + 1}")

    def _load_iteration(self, m_path: Path, z_path: Path) -> tuple:
        """Load m and z tensors from files"""
        m = torch.load(m_path, map_location=device)
        z = torch.load(z_path, map_location=device)

        # Remove batch dimension if present
        if m.dim() == 4 and m.size(0) == 1:
            m = m.squeeze(0)
        if z.dim() == 4 and z.size(0) == 1:
            z = z.squeeze(0)

        print(f"          üìè Loaded tensor shapes: m={list(m.shape)}, z={list(z.shape)}")

        # Apply cluster size reduction (only to MSA dimension, not sequence length)
        if m.shape[0] > args.reduced_cluster_size:
            m = m[:args.reduced_cluster_size]
            print(f"          ‚úÇÔ∏è  Reduced cluster size to {args.reduced_cluster_size}")

        return m, z.squeeze(0)
        if z.dim() == 4 and z.size(0) == 1:
            z = z.squeeze(0)

        # Apply cluster size reduction
        m = m[:args.reduced_cluster_size]

        return m, z

    def _run_evoformer_iter(self, m_path: Path, z_path: Path, output_dir: Path) -> bool:
        """Run the evoformer iteration script"""

        try:
            if self.iter_script.suffix == '.sh':
                # Shell script version - your evoformer_iter_script.sh
                cmd = [
                    'bash', str(self.iter_script),
                    '--m_path', str(m_path),
                    '--z_path', str(z_path),
                    '--output_dir', str(output_dir),
                    '--config_preset', self.config_preset,
                    '--device', self.device
                ]

                env = os.environ.copy()
                # Add PYTHONPATH for any Python calls within the shell script
                if 'PYTHONPATH' in env:
                    env['PYTHONPATH'] = f"{str(self.project_root)}:{env['PYTHONPATH']}"
                else:
                    env['PYTHONPATH'] = str(self.project_root)

            else:
                # Python script version - run_evoformer_iter.py
                cmd = [
                    sys.executable, str(self.iter_script),
                    '--m_path', str(m_path),
                    '--z_path', str(z_path),
                    '--output_dir', str(output_dir),
                    '--config_preset', self.config_preset,
                    '--device', self.device
                ]
                env = os.environ.copy()
                # Add PYTHONPATH
                if 'PYTHONPATH' in env:
                    env['PYTHONPATH'] = f"{str(self.project_root)}:{env['PYTHONPATH']}"
                else:
                    env['PYTHONPATH'] = str(self.project_root)

            print(f"        üîß Command: {' '.join(cmd)}")
            print(f"        üìÅ Working dir: {self.project_root}")
            print(f"        üìÇ Input files:")
            print(f"           M: {m_path} (exists: {m_path.exists()})")
            print(f"           Z: {z_path} (exists: {z_path.exists()})")
            print(f"        üìÇ Output dir: {output_dir}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # Increase timeout to 10 minutes
                cwd=str(self.project_root),
                env=env
            )

            print(f"        üìä Return code: {result.returncode}")

            # Always show stdout and stderr for debugging
            if result.stdout:
                print(f"        üìÑ STDOUT:")
                stdout_lines = result.stdout.strip().split('\n')
                for line in stdout_lines[-10:]:  # Show last 10 lines
                    print(f"           {line}")

            if result.stderr:
                print(f"        ‚ùå STDERR:")
                stderr_lines = result.stderr.strip().split('\n')
                for line in stderr_lines[-10:]:  # Show last 10 lines
                    print(f"           {line}")

            if result.returncode == 0:
                # Check if output files were actually created
                m_next = output_dir / f"m_block_{int(m_path.stem.split('_')[-1]) + 1}.pt"
                z_next = output_dir / f"z_block_{int(z_path.stem.split('_')[-1]) + 1}.pt"

                print(f"        üîç Checking for output files:")
                print(f"           Expected M: {m_next} (exists: {m_next.exists()})")
                print(f"           Expected Z: {z_next} (exists: {z_next.exists()})")

                if m_next.exists() and z_next.exists():
                    print(f"        ‚úÖ Output files confirmed")
                    return True
                else:
                    print(f"        ‚ùå Output files not found despite success return code")
                    return False
            else:
                print(f"        ‚ùå Evoformer iteration failed with return code {result.returncode}")
                return False

        except subprocess.TimeoutExpired:
            print(f"        ‚ùå Evoformer iteration timed out after 10 minutes")
            return False
        except Exception as e:
            print(f"        ‚ùå Error running evoformer iteration: {e}")
            import traceback
            traceback.print_exc()
            return False


# Initialize the iteration manager
iter_manager = EvoformerIterationManager(PROJECT_ROOT, args.config_preset, args.device)


def train_step(protein_id):
    """Single training step for one protein with dynamic iteration generation"""
    print(f"  üß¨ Training {protein_id}")

    try:
        # Load initial state (t=0)
        m_init, z_init = load_initial_input(protein_id)
        print(f"    üìä Initial shapes: m={m_init.shape}, z={z_init.shape}")

        ode_state = (m_init, z_init)
        total_loss = 0
        num_comparisons = 0

        with autocast(enabled=args.use_amp):
            clear_memory()

            print(f"    üßÆ Starting ODE integration with {len(t_grid)} time points...")

            # Debug: Check shapes before ODE integration
            print(f"    üìè Input to ODE: m={m_init.shape}, z={z_init.shape}")

            # Integrate Neural ODE across time points
            if args.reduced_precision_integration:
                pred_trajectory = odeint(
                    ode_func, ode_state, t_grid, method=args.integrator, rtol=1e-2, atol=1e-2
                )
            else:
                pred_trajectory = odeint(
                    ode_func, ode_state, t_grid, method=args.integrator
                )

            # Debug: Check shapes after ODE integration
            print(f"    üìè Output from ODE: m={pred_trajectory[0].shape}, z={pred_trajectory[1].shape}")

            # Compare predictions with ground truth at multiple time points
            # FIXED: Start from timestep 0, generate timestep 1, 2, 3, etc. sequentially
            for i in range(1, min(len(t_grid), args.num_time_points)):
                try:
                    # Generate the ground truth for this time step using evoformer_iter
                    # We need timestep i, so we generate it from timestep i-1
                    print(f"      üéØ Comparing time step {i}/{len(t_grid) - 1}")

                    # Generate from previous timestep (i-1) to get current timestep (i)
                    target_m, target_z = iter_manager.generate_next_iteration(protein_id, i - 1)

                    # Get ODE prediction at this time point
                    pred_m = pred_trajectory[0][i]
                    pred_z = pred_trajectory[1][i]

                    print(f"        üìè Pred shapes: m={pred_m.shape}, z={pred_z.shape}")
                    print(f"        üìè Target shapes: m={target_m.shape}, z={target_z.shape}")

                    # Compute loss for this time step
                    step_loss, msa_loss, pair_loss = balanced_loss_fn(pred_m, target_m, pred_z, target_z)
                    total_loss += step_loss
                    num_comparisons += 1

                    print(f"        üìä Step {i} Loss: Total={step_loss:.4f}, MSA={msa_loss:.4f}, Pair={pair_loss:.4f}")

                    # Clean up targets immediately to save memory
                    del target_m, target_z

                except Exception as e:
                    print(f"        ‚ö†Ô∏è  Could not generate/compare time step {i}: {e}")
                    # Continue with other time steps
                    continue

            # Average the loss across time steps
            if num_comparisons > 0:
                total_loss = total_loss / num_comparisons
                print(f"    üìä Average Loss across {num_comparisons} time steps: {total_loss:.4f}")
            else:
                print(f"    ‚ö†Ô∏è  No valid time step comparisons - using dummy loss")
                # If no evoformer iterations worked, use a simple dummy loss to keep training going
                dummy_target_m = m_init + torch.randn_like(m_init) * 0.01
                dummy_target_z = z_init + torch.randn_like(z_init) * 0.01
                pred_m = pred_trajectory[0][-1]  # Use final prediction
                pred_z = pred_trajectory[1][-1]
                total_loss, _, _ = balanced_loss_fn(pred_m, dummy_target_m, pred_z, dummy_target_z)
                print(f"    üìä Dummy Loss: {total_loss:.4f}")

        # Clean up
        del pred_trajectory, ode_state, m_init, z_init
        clear_memory()

        return total_loss

    except Exception as e:
        print(f"    ‚ùå Error with {protein_id}: {e}")
        return torch.tensor(0.0, device=device)


def train():
    """Main training loop"""
    dataset = get_dataset(DATA_DIR)

    if not dataset:
        print("‚ùå No proteins found in data directory!")
        return

    # Filter to test protein if specified
    if args.test_protein and args.test_protein in dataset:
        dataset = [args.test_protein]
        print(f"Testing on single protein: {args.test_protein}")

    print(f"Training on {len(dataset)} proteins from {DATA_DIR}")

    training_history = []

    for epoch in range(epochs):
        print(f"\nüîÑ Epoch {epoch + 1}/{epochs}")
        print("=" * 50)

        clear_memory()
        print_memory_stats(f"Start of Epoch {epoch + 1}")

        epoch_loss = 0
        successful_proteins = 0

        for protein_id in dataset:
            optimizer.zero_grad()

            loss = train_step(protein_id)

            if isinstance(loss, torch.Tensor) and loss.item() > 0:
                # Backpropagate
                if args.use_amp:
                    scaler.scale(loss).backward()
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(ode_func.parameters(), max_norm=1.0)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(ode_func.parameters(), max_norm=1.0)
                    optimizer.step()

                epoch_loss += loss.item()
                successful_proteins += 1

            print_memory_stats(f"After {protein_id}")

        avg_loss = epoch_loss / max(successful_proteins, 1)
        training_history.append(avg_loss)

        print(f"\nüìä Epoch {epoch + 1} Summary:")
        print(f"   Average Loss: {avg_loss:.6f}")
        print(f"   Successful proteins: {successful_proteins}/{len(dataset)}")

        # Save checkpoint
        checkpoint_path = os.path.join(OUTPUT_DIR, f"evoformer_ode_epoch_{epoch + 1}.pt")
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': ode_func.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': avg_loss,
            'args': vars(args),
            'training_history': training_history
        }, checkpoint_path)

        print(f"üíæ Checkpoint saved: {checkpoint_path}")

    # Save final summary
    summary = {
        'final_loss': training_history[-1] if training_history else 0,
        'training_history': training_history,
        'total_proteins': len(dataset),
        'successful_proteins': successful_proteins,
        'configuration': vars(args)
    }

    summary_path = os.path.join(OUTPUT_DIR, "training_summary.json")
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)

    print(f"\nüéØ Training Complete!")
    print(f"üìà Loss progression: {training_history}")
    print(f"üìÑ Summary saved: {summary_path}")


if __name__ == "__main__":
    try:
        train()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Training interrupted by user")
    except Exception as e:
        print(f"‚ùå Training failed: {e}")
        import traceback

        traceback.print_exc()